# ----- required imports -----

import os
import json
import ollama

# ----- helper functions -----

def start_model():
    """
    attempts to start and return an ollama model, else returns none
    """
    try:
        client = ollama.Client()
        return client
    except:
        return None


def parse_generated_log(target_filepath, entry_num="1"):
    """
    helper function to extract relevant fields
    from the generated log file for validation
    """
    if not os.path.isfile(target_filepath):
        raise FileNotFoundError(
            f"Error: Log file at filepath {target_filepath} does not exist."
        )
    else:
        with open(target_filepath, "r") as log_file:
            try:
                tem = json.load(log_file)
                return {
                    "clean_html_body_local_file_path": tem[entry_num][
                        "clean_html_body_local_file_path"
                    ],
                    "enriched_data_entry_json": tem[entry_num][
                        "enriched_data_entry_json"
                    ],
                    "sift_2_validation_status": tem[entry_num][
                        "sift_2_validation_status"
                    ],
                    "sift_2_error_array": tem[entry_num]["sift_2_error_array"],
                }
            except json.JSONDecodeError as e:
                raise ValueError(f"Error: Unable to decode JSON from the log file: {e}")


def load_clean_html(html_target_filepath):
    """
    load the sanitised html file
    """
    html_content = ""
    if not os.path.isfile(html_target_filepath):
        raise FileNotFoundError(
            f"Error: Txt file at the filepath {html_target_filepath} does not exist."
        )
    else:
        try:
            with open(html_target_filepath, "r", encoding="utf-8") as html_file:
                html_content = html_file.read()
        except IOError as e:
            raise IOError(f"Error: Unable to read the txt file: {e}")
        return html_content


def write_agent_log(
    target_filepath, field_value, field_name="agent_log", entry_num="1"
):
    """
    writes log data generated by the agentic workflow to the
    json at the specified filepath
    """
    try:
        with open(target_filepath, "r") as json_file:
            data = json.load(json_file)[entry_num]
        wrapper = {
            entry_num: {
                "sift_1_validation_status": data["sift_1_validation_status"],
                "sift_2_validation_status": data["sift_2_validation_status"],
                "clean_html_body_local_file_path": data[
                    "clean_html_body_local_file_path"
                ],
                "sift_1_error_array": data["sift_1_error_array"],
                "sift_2_error_array": data["sift_2_error_array"],
                field_name: field_value,
                "enriched_data_entry_json": data["enriched_data_entry_json"],
            }
        }
        with open(target_filepath, "w") as json_file:
            json.dump(wrapper, json_file, indent=4)
        print(
            f"Data successfully written to JSON at the filepath {target_filepath}\nField '{field_name}' successfully appended."
        )
    except Exception as e:
        print(
            f"Error: Unable to read or write to the JSON at the specified filepath: {e}"
        )


def generate_dsl_code(client, example_dsl_code, separate_prompt):
    """
    generates DSL code based on an example DSL code and a separate prompt.
    """

    prompt = f"""
    You are an AI tasked with generating DSL code.

    Example DSL code:

    {example_dsl_code}

    Based on this example and the following prompt, generate new DSL code:

    {separate_prompt}
    
    Ensure that the generated code adheres to the syntax specifications of the DSL.
    """

    print(prompt)

    response = client.generate(prompt=prompt, model="codellama")

    print("------")

    print(response)

    response_text = response["response"].strip()

    return response_text


def execute_agentic_workflow(log_filepath):
    """
    wrapper function that performs agentic
    validation on the specified data, returning
    a boolean upon function execution state
    """
    client_model = start_model()
    
    # Example DSL code and separate prompt can be defined here or passed in.
    example_dsl_code = "<your_example_dsl_code_here>"
    separate_prompt = "<your_separate_prompt_here>"
    
    if client_model:
        generated_dsl_code = generate_dsl_code(client_model, example_dsl_code, separate_prompt)
        
        # Write generated DSL code back to log or handle it as needed.
        write_agent_log(log_filepath, generated_dsl_code)
        
        return True
    else:
        print("Error: Unable to generate ollama model.")
        return False


# ----- sample execution code -----

if __name__ == "__main__":
    TARGET_FILEPATH = "generated_log/log.json"

    logged_data = parse_generated_log(TARGET_FILEPATH)

    # Example DSL code and separate prompt can be defined here or passed in.
    example_dsl_code = "<your_example_dsl_code_here>"
    separate_prompt = "<your_separate_prompt_here>"

    client_model = start_model()

    if client_model:
        print("Generating DSL code now...")
        
        generated_dsl_code = generate_dsl_code(client_model, example_dsl_code, separate_prompt)
        
        write_agent_log(TARGET_FILEPATH, generated_dsl_code)
        
        print("DSL code generation complete.")
    
    else:
        print("Error: Unable to generate ollama model.")
